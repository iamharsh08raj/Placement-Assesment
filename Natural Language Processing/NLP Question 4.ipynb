{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beea19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\8092\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a890e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    \n",
    "    return sentences, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb63fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_scores(sentences, words):\n",
    "    # Calculate word frequency distribution\n",
    "    word_frequency = FreqDist(words)\n",
    "    \n",
    "    # Calculate sentence scores based on word frequency\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        score = sum(word_frequency[word.lower()] for word in word_tokenize(sentence) if word.lower() in word_frequency)\n",
    "        sentence_scores[i] = score\n",
    "    \n",
    "    return sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb42609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(sentences, sentence_scores, num_sentences):\n",
    "    # Sort sentences based on their scores in descending order\n",
    "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select top N sentences with highest scores to create the summary\n",
    "    selected_sentences = sorted_sentences[:num_sentences]\n",
    "    summary = \" \".join([sentences[index] for index, _ in selected_sentences])\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4de8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text from a file\n",
    "with open(\"input.txt\", \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85db91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "sentences, words = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bac5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentence scores\n",
    "sentence_scores = calculate_sentence_scores(sentences, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e3e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary\n",
    "summary = generate_summary(sentences, sentence_scores, num_sentences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1dc4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP)â€¯ \n",
      "Natural language processing is a branch of artificial intelligence that enables computers to analyze, understand, and drive meaning from a human language using machine learning and respond to it. It determines whether the data is positive, negative, or neutral.â€¯ \n",
      "\n",
      " \n",
      "\n",
      "Some of the real-world applications of sentiment analysis are:â€¯ \n",
      "\n",
      "Customer supportâ€¯ \n",
      "Customer feedbackâ€¯ \n",
      "Brand monitoringâ€¯ \n",
      "Product analysisâ€¯ \n",
      "Market researchâ€¯ \n",
      "Conclusion:â€¯ \n",
      "We have discussed natural language processing and what common tasks it performs in natural language processing. Identifying named entities helps identify the critical element in the text, which can help sort the unstructured data and find valuable information.â€¯â€¯ \n",
      "Sentiment analysis \n",
      "Sentiment analysis, also referred to as opinion mining, uses natural language processing to find and extract sentiments from the text.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
